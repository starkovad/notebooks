{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Загрузка датасета tiny-imagenet-200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import zipfile\n",
    "\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "def download_tinyImg200(path,\n",
    "                        url='http://cs231n.stanford.edu/tiny-imagenet-200.zip',\n",
    "                        file_name='tiny-imagenet-200.zip'):\n",
    "    \"\"\"\n",
    "    download images from url to full_path with urlretrieve\n",
    "    \"\"\"\n",
    "    \n",
    "    if not os.path.exists(path):\n",
    "        # create dir if path not exist\n",
    "        os.mkdir(path)\n",
    "        \n",
    "    full_path = os.path.join(path, file_name)\n",
    "        \n",
    "    urlretrieve(url, full_path)\n",
    "    \n",
    "    return full_path\n",
    "    \n",
    "def zip_unpack(full_path):\n",
    "    \"\"\"\n",
    "    unpack zip file from full_path\n",
    "    \"\"\"\n",
    "    zip_ref = zipfile.ZipFile(full_path, 'r')\n",
    "    zip_ref.extractall()\n",
    "    zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/starkov/imagenet/'\n",
    "full_path = download_tinyImg200(path)\n",
    "\n",
    "zip_unpack(full_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1. Resize изображений, cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "\n",
    "def resize_img(image_path, size):\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.resize(img,(size,size), interpolation = cv2.INTER_CUBIC)\n",
    "    cv2.imwrite(image_path,img)\n",
    "\n",
    "def resize_all(tiny_path='./test_tiny/',\n",
    "               train_path='train/*/*/*',\n",
    "               val_path='val/*/*'):\n",
    "    \n",
    "    train = glob.glob(f'{tiny_path}{train_path}')\n",
    "    val = glob.glob(f'{tiny_path}{val_path}')\n",
    "    \n",
    "    for img in train:\n",
    "        resize_img(img, 224)\n",
    "        \n",
    "    for img in val:\n",
    "        resize_img(img, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Создание dataloader'ов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloaders_list(tiny_test_path='./test_tiny/',\n",
    "                         num_workers={'train': 0,'val': 0},\n",
    "                         split_tiny_path=['train', 'val'],\n",
    "                         data_transforms={'train': None, 'val': None},\n",
    "                         batch_size=40):\n",
    "    \n",
    "    full_path = {split: os.path.join(tiny_test_path, split) for split in split_tiny_path}\n",
    "    \n",
    "    \n",
    "    datasets = {split: torchvision.datasets.ImageFolder(full_path[split],\n",
    "                                                             data_transforms[split]) for split in split_tiny_path}\n",
    "    sizes = {split: len(datasets[split]) for split in split_tiny_path}\n",
    "    \n",
    "   \n",
    "    dataloaders = {split: torch.utils.data.DataLoader(datasets[split],\n",
    "                                                       batch_size=batch_size,\n",
    "                                                       shuffle=True,\n",
    "                                                       num_workers=num_workers[split]) for split in split_tiny_path}\n",
    "    \n",
    "    return [dataloaders, sizes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "workers = {'train': 60,\n",
    "           'val': 2}\n",
    "\n",
    "transformation = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomRotation(20),\n",
    "        transforms.RandomHorizontalFlip(0.5),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.4802, 0.4481, 0.3975], [0.2302, 0.2265, 0.2262]),\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.4802, 0.4481, 0.3975], [0.2302, 0.2265, 0.2262]),\n",
    "    ])\n",
    "}\n",
    "\n",
    "dataloaders, sizes = get_dataloaders_list(num_workers=workers,\n",
    "                                          data_transforms=transformation, \n",
    "                                          batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 100000, 'val': 10000}"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Обучение сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# в терминале:\n",
    "# sudo fallocate -l 10G /swapfile\n",
    "# sudo chmod 600 /swapfile\n",
    "# sudo mkswap /swapfile\n",
    "# sudo swapon /swapfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "import torch.optim as opt\n",
    "import torch.nn as nn\n",
    "\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def train_model(dataloaders,\n",
    "                dataset_sizes,\n",
    "                model_name='resnet18',\n",
    "                optimizer_name='SGD',\n",
    "                criterion=nn.CrossEntropyLoss(),\n",
    "                num_epochs=10,\n",
    "                pretrained=False,\n",
    "                **opt_params):\n",
    "    \n",
    "    model = models.__dict__[model_name](pretrained=pretrained)\n",
    "    model.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "    model.fc.out_features = 200\n",
    "    \n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    \n",
    "    optimizer = opt.__dict__[optimizer_name](model.parameters(), **opt_params)\n",
    "\n",
    "    best_model = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    best = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "        print('-' * 10)\n",
    "        \n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            \n",
    "            for i,(inputs, labels) in enumerate(dataloaders[phase]):\n",
    "                \n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                \n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                \n",
    "                print(f'\\rIter: {i+1}/{len(dataloaders[phase])} current loss: {loss.item() * inputs.size(0)}', \n",
    "                      end='', \n",
    "                      flush=True)\n",
    "                \n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "            \n",
    "            if phase == 'train':\n",
    "                avg_loss = epoch_loss\n",
    "                t_acc = epoch_acc\n",
    "            else:\n",
    "                val_loss = epoch_loss\n",
    "                val_acc = epoch_acc\n",
    "            \n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best = epoch + 1\n",
    "                best_model = copy.deepcopy(model.state_dict())\n",
    "        \n",
    "        print(f'Train ---- loss: {avg_loss} accuracy: {t_acc*100}%')\n",
    "        print(f'Validation ---- loss: {val_loss} accuracy: {val_acc*100}%')\n",
    "        print()\n",
    "    \n",
    "    \n",
    "    print(f'Validation best accuracy: {best_acc*100}%')\n",
    "    \n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "----------\n",
      "Iter: 100/100 current loss: 467.359113693237383Train ---- loss: 5.268958933830262 accuracy: 3.314%\n",
      "Validation ---- loss: 4.717855415344238 accuracy: 6.13%\n",
      "\n",
      "Epoch 2/10\n",
      "----------\n",
      "Iter: 100/100 current loss: 405.026578903198248Train ---- loss: 4.51236998796463 accuracy: 8.045%\n",
      "Validation ---- loss: 4.29373037815094 accuracy: 10.440000000000001%\n",
      "\n",
      "Epoch 3/10\n",
      "----------\n",
      "Iter: 100/100 current loss: 409.9702358245849634Train ---- loss: 4.164669118165969 accuracy: 11.999%\n",
      "Validation ---- loss: 4.088132531642914 accuracy: 12.41%\n",
      "\n",
      "Epoch 4/10\n",
      "----------\n",
      "Iter: 100/100 current loss: 364.5824909210205096Train ---- loss: 3.9448413727283476 accuracy: 14.953%\n",
      "Validation ---- loss: 3.835593304634094 accuracy: 16.05%\n",
      "\n",
      "Epoch 5/10\n",
      "----------\n",
      "Iter: 100/100 current loss: 373.5578060150146534Train ---- loss: 3.7851715466976166 accuracy: 17.321%\n",
      "Validation ---- loss: 3.7537241864204405 accuracy: 17.27%\n",
      "\n",
      "Epoch 6/10\n",
      "----------\n",
      "Iter: 100/100 current loss: 366.2917852401733453Train ---- loss: 3.647865221261978 accuracy: 19.43%\n",
      "Validation ---- loss: 3.605828785896301 accuracy: 20.23%\n",
      "\n",
      "Epoch 7/10\n",
      "----------\n",
      "Iter: 100/100 current loss: 353.976035118103624Train ---- loss: 3.526028016328812 accuracy: 21.363%\n",
      "Validation ---- loss: 3.556571764945984 accuracy: 20.68%\n",
      "\n",
      "Epoch 8/10\n",
      "----------\n",
      "Iter: 100/100 current loss: 342.815494537353599Train ---- loss: 3.417534135580063 accuracy: 23.121%\n",
      "Validation ---- loss: 3.3922532057762145 accuracy: 23.200000000000003%\n",
      "\n",
      "Epoch 9/10\n",
      "----------\n",
      "Iter: 100/100 current loss: 310.6852054595947314Train ---- loss: 3.3199438436031343 accuracy: 24.671000000000003%\n",
      "Validation ---- loss: 3.317596619129181 accuracy: 24.38%\n",
      "\n",
      "Epoch 10/10\n",
      "----------\n",
      "Iter: 100/100 current loss: 323.400998115539552Train ---- loss: 3.230316465139389 accuracy: 26.332%\n",
      "Validation ---- loss: 3.240683946609497 accuracy: 25.89%\n",
      "\n",
      "Validation best accuracy: 25.89%\n"
     ]
    }
   ],
   "source": [
    "best_model = train_model(dataloaders,\n",
    "                         sizes,\n",
    "                         num_epochs=10, \n",
    "                         pretrained=False,\n",
    "                         lr=0.001,\n",
    "                         momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "----------\n",
      "Iter: 100/100 current loss: 308.981752395629987Train ---- loss: 4.3620688700675965 accuracy: 15.023%\n",
      "Validation ---- loss: 3.049084939956665 accuracy: 30.29%\n",
      "\n",
      "Epoch 2/10\n",
      "----------\n",
      "Iter: 100/100 current loss: 197.3064064979553264Train ---- loss: 2.5109217983484267 accuracy: 41.064%\n",
      "Validation ---- loss: 2.1105877387523653 accuracy: 48.52%\n",
      "\n",
      "Epoch 3/10\n",
      "----------\n",
      "Iter: 100/100 current loss: 152.3953080177307915Train ---- loss: 1.927002214550972 accuracy: 53.052%\n",
      "Validation ---- loss: 1.7673091435432433 accuracy: 56.089999999999996%\n",
      "\n",
      "Epoch 4/10\n",
      "----------\n",
      "Iter: 100/100 current loss: 165.3261423110962724Train ---- loss: 1.6266151379346847 accuracy: 59.631%\n",
      "Validation ---- loss: 1.5819066548347473 accuracy: 60.150000000000006%\n",
      "\n",
      "Epoch 5/10\n",
      "----------\n",
      "Iter: 100/100 current loss: 153.193891048431466Train ---- loss: 1.4281135547757149 accuracy: 64.059%\n",
      "Validation ---- loss: 1.4637005400657654 accuracy: 62.760000000000005%\n",
      "\n",
      "Epoch 6/10\n",
      "----------\n",
      "Iter: 100/100 current loss: 113.3386850357055722Train ---- loss: 1.2861955409049988 accuracy: 67.258%\n",
      "Validation ---- loss: 1.4044817006587982 accuracy: 64.09%\n",
      "\n",
      "Epoch 7/10\n",
      "----------\n",
      "Iter: 100/100 current loss: 155.362808704376224Train ---- loss: 1.1688851237297058 accuracy: 70.036%\n",
      "Validation ---- loss: 1.3404188400506973 accuracy: 65.84%\n",
      "\n",
      "Epoch 8/10\n",
      "----------\n",
      "Iter: 100/100 current loss: 111.140894889831547Train ---- loss: 1.0710028958916664 accuracy: 72.38799999999999%\n",
      "Validation ---- loss: 1.300851244330406 accuracy: 66.86999999999999%\n",
      "\n",
      "Epoch 9/10\n",
      "----------\n",
      "Iter: 100/100 current loss: 129.070901870727542Train ---- loss: 0.9852259471416474 accuracy: 74.32600000000001%\n",
      "Validation ---- loss: 1.2895407164096833 accuracy: 67.17%\n",
      "\n",
      "Epoch 10/10\n",
      "----------\n",
      "Iter: 100/100 current loss: 159.969437122344975Train ---- loss: 0.911751403093338 accuracy: 76.181%\n",
      "Validation ---- loss: 1.2637507939338684 accuracy: 67.92%\n",
      "\n",
      "Validation best accuracy: 67.92%\n"
     ]
    }
   ],
   "source": [
    "best_model = train_model(dataloaders,\n",
    "                         sizes,\n",
    "                         num_epochs=10, \n",
    "                         pretrained=True,\n",
    "                         lr=0.001,\n",
    "                         momentum=0.9)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
